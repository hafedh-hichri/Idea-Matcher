{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import logging\n",
    "from gensim.models import TfidfModel\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import download\n",
    "from gensim.similarities import SparseTermSimilarityMatrix, WordEmbeddingSimilarityIndex\n",
    "import gensim.downloader as api\n",
    "import pickle \n",
    "from gensim.corpora import Dictionary\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ['Title', 'Type', 'Sector','Key words', 'Problem/Opportunity', \n",
    "#           'Description', 'Added Value','Impact']\n",
    "\n",
    "columns = [\"Key words\",\"Title\",\"Description\"]\n",
    "\n",
    "\n",
    "path = \"./dependencies/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hhich\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Initialize logging.\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "\n",
    "# Import and download stopwords from NLTK.\n",
    "download('stopwords')  # Download stopwords list.\n",
    "stop_words = stopwords.words('english')\n",
    "portuguese = stopwords.words('portuguese')\n",
    "stop_words.extend(portuguese)\n",
    "\n",
    "\n",
    "def file_path(column, variable_name, path=path):\n",
    "    return path+\"\".join(column.split())+\"_\"+variable_name+\".pickle\"\n",
    "\n",
    "\n",
    "df = pd.read_excel('./Example of the original database (1).xlsx')\n",
    "df = df.iloc[:, :11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Employee Name</th>\n",
       "      <th>Title</th>\n",
       "      <th>Type</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Key words</th>\n",
       "      <th>Problem/Opportunity</th>\n",
       "      <th>Description</th>\n",
       "      <th>Added Value</th>\n",
       "      <th>Impact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Preston</td>\n",
       "      <td>Crawford</td>\n",
       "      <td>Preston Crawford</td>\n",
       "      <td>Brand Websites &amp; Web Pages</td>\n",
       "      <td>Product/Service</td>\n",
       "      <td>Marketing Digital</td>\n",
       "      <td>Website, Business, commerce</td>\n",
       "      <td>grow your business and increase leads</td>\n",
       "      <td>A confident online presence is essential and c...</td>\n",
       "      <td>Business growth, confidance of the clients, be...</td>\n",
       "      <td>Profit growth, customer's loyalty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Violet</td>\n",
       "      <td>Phillips</td>\n",
       "      <td>Violet Phillips</td>\n",
       "      <td>Microsites &amp; Topic Hubs</td>\n",
       "      <td>Product/Service</td>\n",
       "      <td>Marketing Digital</td>\n",
       "      <td>Microsite, Business, contents</td>\n",
       "      <td>focuses on branded content or a single topic  ...</td>\n",
       "      <td>A microsite is a website separate from your ma...</td>\n",
       "      <td>Being more professional, details, innovative</td>\n",
       "      <td>specific contents and well organized business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Frederick</td>\n",
       "      <td>Walker</td>\n",
       "      <td>Frederick Walker</td>\n",
       "      <td>Blogs &amp; Blog Posts</td>\n",
       "      <td>Product/Service</td>\n",
       "      <td>Marketing Digital</td>\n",
       "      <td>Blog, contents, search engine</td>\n",
       "      <td>connect with your customers and answer their p...</td>\n",
       "      <td>The main purpose of a blog is to connect with ...</td>\n",
       "      <td>blog with high-quality and relevant blog posts...</td>\n",
       "      <td>source of content that can be repurposed into ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wilson</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>Wilson Henderson</td>\n",
       "      <td>Videos</td>\n",
       "      <td>Product/Service</td>\n",
       "      <td>Marketing Digital</td>\n",
       "      <td>Video, contents, audiance</td>\n",
       "      <td>explainer, onboarding, promotional, social, a...</td>\n",
       "      <td>Another common digital marketing idea is to in...</td>\n",
       "      <td>a versatile and shareable tool to reach their ...</td>\n",
       "      <td>being efficient and convenient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thomas</td>\n",
       "      <td>Bailey</td>\n",
       "      <td>Thomas Bailey</td>\n",
       "      <td>Ebooks</td>\n",
       "      <td>Product/Service</td>\n",
       "      <td>Marketing Digital</td>\n",
       "      <td>Ebook, Digital, audiance</td>\n",
       "      <td>They can be downloadable gifts to prospects an...</td>\n",
       "      <td>EBooks are a great way to strengthen your bran...</td>\n",
       "      <td>strengthen your brand and reach a broad audience</td>\n",
       "      <td>feels like a personal object of value you’re ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  First Name  Last Name     Employee Name                       Title  \\\n",
       "0    Preston   Crawford  Preston Crawford  Brand Websites & Web Pages   \n",
       "1     Violet   Phillips   Violet Phillips     Microsites & Topic Hubs   \n",
       "2  Frederick     Walker  Frederick Walker          Blogs & Blog Posts   \n",
       "3     Wilson  Henderson  Wilson Henderson                      Videos   \n",
       "4     Thomas     Bailey     Thomas Bailey                      Ebooks   \n",
       "\n",
       "              Type              Sector                      Key words  \\\n",
       "0  Product/Service  Marketing Digital     Website, Business, commerce   \n",
       "1  Product/Service  Marketing Digital   Microsite, Business, contents   \n",
       "2  Product/Service  Marketing Digital   Blog, contents, search engine   \n",
       "3  Product/Service  Marketing Digital       Video, contents, audiance   \n",
       "4  Product/Service  Marketing Digital        Ebook, Digital, audiance   \n",
       "\n",
       "                                 Problem/Opportunity  \\\n",
       "0              grow your business and increase leads   \n",
       "1  focuses on branded content or a single topic  ...   \n",
       "2  connect with your customers and answer their p...   \n",
       "3   explainer, onboarding, promotional, social, a...   \n",
       "4  They can be downloadable gifts to prospects an...   \n",
       "\n",
       "                                         Description  \\\n",
       "0  A confident online presence is essential and c...   \n",
       "1  A microsite is a website separate from your ma...   \n",
       "2  The main purpose of a blog is to connect with ...   \n",
       "3  Another common digital marketing idea is to in...   \n",
       "4  EBooks are a great way to strengthen your bran...   \n",
       "\n",
       "                                         Added Value  \\\n",
       "0  Business growth, confidance of the clients, be...   \n",
       "1       Being more professional, details, innovative   \n",
       "2  blog with high-quality and relevant blog posts...   \n",
       "3  a versatile and shareable tool to reach their ...   \n",
       "4   strengthen your brand and reach a broad audience   \n",
       "\n",
       "                                              Impact  \n",
       "0                  Profit growth, customer's loyalty  \n",
       "1      specific contents and well organized business  \n",
       "2  source of content that can be repurposed into ...  \n",
       "3                     being efficient and convenient  \n",
       "4   feels like a personal object of value you’re ...  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-29 23:41:31,456 : INFO : loading projection weights from C:\\Users\\hhich/gensim-data\\word2vec-google-news-300\\word2vec-google-news-300.gz\n",
      "2022-12-29 23:42:57,799 : INFO : KeyedVectors lifecycle event {'msg': 'loaded (3000000, 300) matrix of type float32 from C:\\\\Users\\\\hhich/gensim-data\\\\word2vec-google-news-300\\\\word2vec-google-news-300.gz', 'binary': True, 'encoding': 'utf8', 'datetime': '2022-12-29T23:42:57.798112', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sentence,stop_words=stop_words):\n",
    "    sentence = str(sentence)\n",
    "    return [w for w in sentence.lower().split() if w not in stop_words]\n",
    "\n",
    "def save_variable(column,variable_name,variable): \n",
    "    p = file_path(column,variable_name,path = path)\n",
    "    with open(p,\"wb\") as f :\n",
    "        pickle.dump(variable,f)\n",
    "        \n",
    "        \n",
    "def createtheAI(column,model=model):\n",
    "    sentences = df[column].values\n",
    "    processed_sentences = []\n",
    "    for sentence in sentences : \n",
    "        processed_sentences.append(preprocess(sentence))\n",
    "    # Define dictionary and create bag of words\n",
    "    dictionary = Dictionary(processed_sentences)\n",
    "    bow = [dictionary.doc2bow(sentence) for sentence in processed_sentences]\n",
    "    # Creating the Term Frequency - Inverse Document Frequency\n",
    "    tfidf = TfidfModel(bow)\n",
    "    tfidf_sentences = [tfidf[sentence] for sentence in bow]\n",
    "    # Term Indexing and Similarity Matrix\n",
    "    termsim_index = WordEmbeddingSimilarityIndex(model)\n",
    "    termsim_matrix = SparseTermSimilarityMatrix(termsim_index, dictionary, tfidf)\n",
    "    # Saving the envirenmental variables\n",
    "    save_variable(column, \"termsim_matrix\", termsim_matrix)\n",
    "    save_variable(column,\"tfidf\",tfidf)\n",
    "    save_variable(column,\"dictionary\",dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> creating the Ai here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-30 00:29:36,465 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2022-12-30 00:29:36,469 : INFO : built Dictionary(14 unique tokens: ['business,', 'commerce', 'website,', 'contents', 'microsite,']...) from 400 documents (total 411 corpus positions)\n",
      "2022-12-30 00:29:36,470 : INFO : Dictionary lifecycle event {'msg': \"built Dictionary(14 unique tokens: ['business,', 'commerce', 'website,', 'contents', 'microsite,']...) from 400 documents (total 411 corpus positions)\", 'datetime': '2022-12-30T00:29:36.470750', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2022-12-30 00:29:36,471 : INFO : collecting document frequencies\n",
      "2022-12-30 00:29:36,472 : INFO : PROGRESS: processing document #0\n",
      "2022-12-30 00:29:36,474 : INFO : TfidfModel lifecycle event {'msg': 'calculated IDF weights for 400 documents and 14 features (411 matrix non-zeros)', 'datetime': '2022-12-30T00:29:36.474257', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'initialize'}\n",
      "2022-12-30 00:29:36,477 : INFO : constructing a sparse term similarity matrix using WordEmbeddingSimilarityIndex(keyedvectors=<gensim.models.keyedvectors.KeyedVectors object at 0x0000025205D88A60>, threshold=0.0, exponent=2.0, kwargs={})\n",
      "2022-12-30 00:29:36,479 : INFO : iterating over 14 columns in tf-idf order\n",
      "100%|██████████| 14/14 [00:01<00:00, 11.02it/s]\n",
      "2022-12-30 00:29:37,752 : INFO : constructed a sparse term similarity matrix with 7.142857% density\n",
      "2022-12-30 00:29:37,765 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2022-12-30 00:29:37,771 : INFO : built Dictionary(710 unique tokens: ['&', 'brand', 'pages', 'web', 'websites']...) from 400 documents (total 1058 corpus positions)\n",
      "2022-12-30 00:29:37,772 : INFO : Dictionary lifecycle event {'msg': \"built Dictionary(710 unique tokens: ['&', 'brand', 'pages', 'web', 'websites']...) from 400 documents (total 1058 corpus positions)\", 'datetime': '2022-12-30T00:29:37.772523', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2022-12-30 00:29:37,776 : INFO : collecting document frequencies\n",
      "2022-12-30 00:29:37,778 : INFO : PROGRESS: processing document #0\n",
      "2022-12-30 00:29:37,782 : INFO : TfidfModel lifecycle event {'msg': 'calculated IDF weights for 400 documents and 710 features (1057 matrix non-zeros)', 'datetime': '2022-12-30T00:29:37.782053', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'initialize'}\n",
      "2022-12-30 00:29:37,788 : INFO : constructing a sparse term similarity matrix using WordEmbeddingSimilarityIndex(keyedvectors=<gensim.models.keyedvectors.KeyedVectors object at 0x0000025205D88A60>, threshold=0.0, exponent=2.0, kwargs={})\n",
      "2022-12-30 00:29:37,791 : INFO : iterating over 710 columns in tf-idf order\n",
      "100%|██████████| 710/710 [02:10<00:00,  5.44it/s]\n",
      "2022-12-30 00:31:48,393 : INFO : constructed a sparse term similarity matrix with 0.407062% density\n",
      "2022-12-30 00:31:48,491 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2022-12-30 00:31:48,511 : INFO : built Dictionary(6095 unique tokens: ['attractive', 'build', 'business', 'businesses', 'company’s']...) from 400 documents (total 17524 corpus positions)\n",
      "2022-12-30 00:31:48,512 : INFO : Dictionary lifecycle event {'msg': \"built Dictionary(6095 unique tokens: ['attractive', 'build', 'business', 'businesses', 'company’s']...) from 400 documents (total 17524 corpus positions)\", 'datetime': '2022-12-30T00:31:48.512676', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2022-12-30 00:31:48,528 : INFO : collecting document frequencies\n",
      "2022-12-30 00:31:48,529 : INFO : PROGRESS: processing document #0\n",
      "2022-12-30 00:31:48,549 : INFO : TfidfModel lifecycle event {'msg': 'calculated IDF weights for 400 documents and 6095 features (15802 matrix non-zeros)', 'datetime': '2022-12-30T00:31:48.549749', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'initialize'}\n",
      "2022-12-30 00:31:48,591 : INFO : constructing a sparse term similarity matrix using WordEmbeddingSimilarityIndex(keyedvectors=<gensim.models.keyedvectors.KeyedVectors object at 0x0000025205D88A60>, threshold=0.0, exponent=2.0, kwargs={})\n",
      "2022-12-30 00:31:48,596 : INFO : iterating over 6095 columns in tf-idf order\n",
      "100%|██████████| 6095/6095 [12:11<00:00,  8.34it/s]\n",
      "2022-12-30 00:43:59,637 : INFO : constructed a sparse term similarity matrix with 0.114089% density\n"
     ]
    }
   ],
   "source": [
    "# Creating and saving the AI here\n",
    "# The columns list contains a list of the columns that we are going to use\n",
    "# Check the first cell to find more info about the columns variable\n",
    "for i in columns:\n",
    "    # Calling the function to create the AI here\n",
    "    # All variables are saved in the dependencies folder\n",
    "    createtheAI(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# similarity between 2 ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads variables \n",
    "def load_variables(column):\n",
    "    l = [\"termsim_matrix\",\"tfidf\",\"dictionary\"]\n",
    "    paths = []\n",
    "    for variable_name in l :\n",
    "        paths.append(file_path(column, variable_name))\n",
    "    with open(paths[0],\"rb\") as f :\n",
    "        termsim_matrix = pickle.load(f)\n",
    "    with open(paths[1],\"rb\") as f :\n",
    "        tfidf = pickle.load(f)\n",
    "    with open(paths[2],\"rb\") as f :\n",
    "        dictionary = pickle.load(f)\n",
    "        \n",
    "    return termsim_matrix, tfidf, dictionary\n",
    "\n",
    "# preprocessing the input\n",
    "\n",
    "\n",
    "def prepare_input(s, dictionary, tfidf):\n",
    "    precessed_input = preprocess(s)\n",
    "    bow_input = dictionary.doc2bow(precessed_input)\n",
    "    tfidf_input = tfidf[bow_input]\n",
    "    return tfidf_input\n",
    "\n",
    "\n",
    "def calculate_similarity(s1, s2, column):\n",
    "    termsim_matrix, tfidf, dictionary = load_variables(\"Title\")\n",
    "    in1 = prepare_input(s1, dictionary, tfidf)\n",
    "    in2 = prepare_input(s2, dictionary, tfidf)\n",
    "    similarity = termsim_matrix.inner_product(\n",
    "        in1, in2, normalized=(True, True))\n",
    "    return similarity\n",
    "\n",
    "\n",
    "def similarity_between_two_rows(idx1, idx2, available_columns=columns):\n",
    "    sim = 0\n",
    "    for column in available_columns:\n",
    "        s1 = df.loc[idx1, column]\n",
    "        s2 = df.loc[idx2, column]\n",
    "        sim += calculate_similarity(s1, s2, column)\n",
    "    sim = sim/len(available_columns)\n",
    "    return sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df)\n",
    "d = {}\n",
    "for i in tqdm(range(0,n-1)):\n",
    "    for j in range(i+1,n):\n",
    "        s = similarity_between_two_rows(i,j,available_columns=columns)\n",
    "        d[f\"{i},{j}\"] = s\n",
    "with open(path+'d.pickle','wb') as f : \n",
    "    pickle.dump(d,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads the dictionary that contains the similarity coefficients\n",
    "def load_sim_dictionary():\n",
    "    with open(path+'d.pickle','rb') as f : \n",
    "        d = pickle.load(f)\n",
    "    return d\n",
    "\n",
    "# Outputs keys for the similar ideas\n",
    "def similar_ideas(thresh=0.1):\n",
    "    d = load_sim_dictionary()\n",
    "    v = list(d.values())\n",
    "    k = list(d.keys())\n",
    "    l = []\n",
    "    for i in range(len(v)): \n",
    "        if v[i] > thresh : \n",
    "            l.append(k[i])\n",
    "    return l \n",
    "\n",
    "\n",
    "# Outputs the names of the users that have similar ideas\n",
    "def users_with_sim_ideas(thresh):\n",
    "    l = similar_ideas(thresh)\n",
    "    names = []\n",
    "    for i in l :\n",
    "        tmp = [] \n",
    "        indexes = i.split(',')\n",
    "        emp1 = df.loc[int(indexes[0]),'Employee Name']\n",
    "        emp2 = df.loc[int(indexes[1]),'Employee Name']\n",
    "        tmp = [emp1,emp2]\n",
    "        names.append(tmp)\n",
    "    return names     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> using the AI here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = load_sim_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43527937"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the previewsly created AI\n",
    "# this is a small example of how to calculate similarity\n",
    "column = 'Title'\n",
    "s1 = 'Social Media Marketing'\n",
    "s2 = 'Launch Social Media Audience Lookalike Ads',\n",
    "calculate_similarity(s1,s2,column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "maximum similarity coeff is 0.5531 \n",
      "which can be found when comaparing the lines 207,215 of the dataset\n"
     ]
    }
   ],
   "source": [
    "k = list(d.keys())\n",
    "v = list(d.values())\n",
    "m = max(v)\n",
    "idx = v.index(m)\n",
    "max_combination = k[idx]\n",
    "print(f\"\"\"\n",
    "maximum similarity coeff is {m:.4} \n",
    "which can be found when comaparing the lines { max_combination } of the dataset\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Rosie Bailey', 'Paul Allen'],\n",
       " ['Luke Williams', 'Steven Walker'],\n",
       " ['Gianna Scott', 'Thomas Stewart'],\n",
       " ['Catherine Grant', 'Eric Perry'],\n",
       " ['Richard Cameron', 'Paul Allen'],\n",
       " ['Richard Morris', 'Alen Johnston'],\n",
       " ['David Edwards', 'Melissa Nelson'],\n",
       " ['Chester Myers', 'Ted Adams'],\n",
       " ['Miranda Stewart', 'Kirsten Kelly'],\n",
       " ['Kellan West', 'Charlie Richardson'],\n",
       " ['Violet Alexander', 'Frederick Lloyd'],\n",
       " ['Violet Alexander', 'Amy Wright'],\n",
       " ['Lucy Owens', 'Rosie Clark'],\n",
       " ['Miley Nelson', 'Kelsey Higgins'],\n",
       " ['Bruce Anderson', 'Miranda Warren'],\n",
       " ['Bruce Anderson', 'Charlie Thompson'],\n",
       " ['Amelia Fowler', 'Edgar Stewart'],\n",
       " ['Sam Carter', 'Caroline Martin'],\n",
       " ['James Sullivan', 'Adelaide Adams'],\n",
       " ['Miranda Warren', 'Charlie Thompson'],\n",
       " ['Kirsten Ellis', 'Lenny Mason']]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_with_sim_ideas(0.4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
